{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = [\n",
    "    (\"hello\", \"xin chào\"),\n",
    "    (\"how are you?\", \"bạn khỏe không?\"),\n",
    "    (\"thank you\", \"cảm ơn bạn\"),\n",
    "    (\"goodbye\", \"tạm biệt\"),\n",
    "    (\"yes\", \"vâng\"),\n",
    "    (\"no\", \"không\"),\n",
    "    (\"what is your name?\", \"tên bạn là gì?\"),\n",
    "    (\"my name is John\", \"tên tôi là John\"),\n",
    "    (\"I love you\", \"tôi yêu bạn\"),\n",
    "    (\"good morning\", \"chào buổi sáng\"),\n",
    "    (\"good night\", \"chúc ngủ ngon\"),\n",
    "    (\"see you later\", \"hẹn gặp lại\"),\n",
    "    (\"how much is this?\", \"cái này giá bao nhiêu?\"),\n",
    "    (\"where is the restroom?\", \"nhà vệ sinh ở đâu?\"),\n",
    "    (\"I am hungry\", \"tôi đói\"),\n",
    "    (\"I am thirsty\", \"tôi khát\"),\n",
    "    (\"I am tired\", \"tôi mệt\"),\n",
    "    (\"can you help me?\", \"bạn có thể giúp tôi không?\"),\n",
    "    (\"where are you from?\", \"bạn đến từ đâu?\"),\n",
    "    (\"I am from Vietnam\", \"tôi đến từ Việt Nam\"),\n",
    "    (\"I like reading books\", \"tôi thích đọc sách\"),\n",
    "    (\"what do you do?\", \"bạn làm nghề gì?\"),\n",
    "    (\"I am a teacher\", \"tôi là giáo viên\"),\n",
    "    (\"I am a student\", \"tôi là sinh viên\"),\n",
    "    (\"what time is it?\", \"bây giờ là mấy giờ?\"),\n",
    "    (\"it is 10 o'clock\", \"bây giờ là 10 giờ\"),\n",
    "    (\"I need a doctor\", \"tôi cần bác sĩ\"),\n",
    "    (\"call the police\", \"gọi cảnh sát\"),\n",
    "    (\"I am lost\", \"tôi bị lạc\"),\n",
    "    (\"I don't understand\", \"tôi không hiểu\"),\n",
    "    (\"please speak slowly\", \"làm ơn nói chậm lại\"),\n",
    "    (\"do you speak English?\", \"bạn có nói tiếng Anh không?\"),\n",
    "    (\"I speak a little English\", \"tôi nói được một chút tiếng Anh\"),\n",
    "    (\"how old are you?\", \"bạn bao nhiêu tuổi?\"),\n",
    "    (\"I am 25 years old\", \"tôi 25 tuổi\"),\n",
    "    (\"do you have any siblings?\", \"bạn có anh chị em không?\"),\n",
    "    (\"I have one brother\", \"tôi có một anh trai\"),\n",
    "    (\"what is your favorite food?\", \"món ăn yêu thích của bạn là gì?\"),\n",
    "    (\"I like pho\", \"tôi thích phở\"),\n",
    "    (\"can you show me the way?\", \"bạn có thể chỉ đường cho tôi không?\"),\n",
    "    (\"I am looking for a hotel\", \"tôi đang tìm khách sạn\"),\n",
    "    (\"how far is it?\", \"nó cách bao xa?\"),\n",
    "    (\"it is about 5 kilometers\", \"nó khoảng 5 km\"),\n",
    "    (\"I am married\", \"tôi đã kết hôn\"),\n",
    "    (\"I am single\", \"tôi độc thân\"),\n",
    "    (\"do you have children?\", \"bạn có con không?\"),\n",
    "    (\"I have two children\", \"tôi có hai con\"),\n",
    "    (\"what is your phone number?\", \"số điện thoại của bạn là gì?\"),\n",
    "    (\"my phone number is 123456789\", \"số điện thoại của tôi là 123456789\"),\n",
    "    (\"I need a taxi\", \"tôi cần taxi\"),\n",
    "    (\"please take me to the airport\", \"làm ơn đưa tôi đến sân bay\"),\n",
    "    (\"where can I buy a ticket?\", \"tôi có thể mua vé ở đâu?\"),\n",
    "    (\"how much does it cost?\", \"nó giá bao nhiêu?\"),\n",
    "    (\"it costs 50 dollars\", \"nó giá 50 đô la\"),\n",
    "    (\"I would like a cup of coffee\", \"tôi muốn một tách cà phê\"),\n",
    "    (\"do you have vegetarian food?\", \"bạn có đồ ăn chay không?\"),\n",
    "    (\"I am allergic to peanuts\", \"tôi bị dị ứng với đậu phộng\"),\n",
    "    (\"can I pay by credit card?\", \"tôi có thể trả bằng thẻ tín dụng không?\"),\n",
    "    (\"where is the nearest ATM?\", \"cây ATM gần nhất ở đâu?\"),\n",
    "    (\"what is the wifi password?\", \"mật khẩu wifi là gì?\"),\n",
    "    (\"I need to charge my phone\", \"tôi cần sạc điện thoại\"),\n",
    "    (\"where can I find a pharmacy?\", \"tôi có thể tìm hiệu thuốc ở đâu?\"),\n",
    "    (\"I have a reservation\", \"tôi có đặt chỗ trước\"),\n",
    "    (\"I need a room for two nights\", \"tôi cần một phòng cho hai đêm\"),\n",
    "    (\"do you have any vacancies?\", \"bạn có phòng trống không?\"),\n",
    "    (\"can I have the menu?\", \"tôi có thể xem thực đơn không?\"),\n",
    "    (\"I would like to order\", \"tôi muốn gọi món\"),\n",
    "    (\"where is the train station?\", \"ga tàu ở đâu?\"),\n",
    "    (\"what time does the train leave?\", \"mấy giờ tàu khởi hành?\"),\n",
    "    (\"how long does the trip take?\", \"chuyến đi mất bao lâu?\"),\n",
    "    (\"I need a map\", \"tôi cần bản đồ\"),\n",
    "    (\"can you recommend a restaurant?\", \"bạn có thể giới thiệu nhà hàng không?\"),\n",
    "    (\"where is the nearest hospital?\", \"bệnh viện gần nhất ở đâu?\"),\n",
    "    (\"I need medical assistance\", \"tôi cần sự trợ giúp y tế\"),\n",
    "    (\"I have a headache\", \"tôi bị đau đầu\"),\n",
    "    (\"I need a pain reliever\", \"tôi cần thuốc giảm đau\"),\n",
    "    (\"is there a pharmacy nearby?\", \"có hiệu thuốc nào gần đây không?\"),\n",
    "    (\"I am allergic to seafood\", \"tôi bị dị ứng hải sản\"),\n",
    "    (\"I would like to go shopping\", \"tôi muốn đi mua sắm\"),\n",
    "    (\"where is the market?\", \"chợ ở đâu?\"),\n",
    "    (\"how much is this shirt?\", \"cái áo này giá bao nhiêu?\"),\n",
    "    (\"do you have a smaller size?\", \"bạn có size nhỏ hơn không?\"),\n",
    "    (\"I would like to try it on\", \"tôi muốn thử nó\"),\n",
    "    (\"do you accept returns?\", \"bạn có chấp nhận đổi trả không?\"),\n",
    "    (\"I would like to exchange this\", \"tôi muốn đổi cái này\"),\n",
    "    (\"can you gift wrap it?\", \"bạn có thể gói quà không?\"),\n",
    "    (\"I am looking for a souvenir\", \"tôi đang tìm một món quà lưu niệm\"),\n",
    "    (\"where can I buy groceries?\", \"tôi có thể mua thực phẩm ở đâu?\"),\n",
    "    (\"I need a bottle of water\", \"tôi cần một chai nước\"),\n",
    "    (\"can I have a receipt?\", \"tôi có thể lấy hóa đơn không?\"),\n",
    "    (\"where is the exit?\", \"lối ra ở đâu?\"),\n",
    "    (\"I need to use the restroom\", \"tôi cần sử dụng nhà vệ sinh\"),\n",
    "    (\"where can I park my car?\", \"tôi có thể đậu xe ở đâu?\"),\n",
    "    (\"do you have parking?\", \"bạn có chỗ đậu xe không?\"),\n",
    "    (\"can you call a cab for me?\", \"bạn có thể gọi taxi cho tôi không?\"),\n",
    "    (\"how do I get to the museum?\", \"tôi đi đến bảo tàng bằng cách nào?\"),\n",
    "    (\"what is the best way to get around?\", \"cách tốt nhất để di chuyển là gì?\")\n",
    "]\n",
    "\n",
    "# Tạo từ điển từ và ngược lại\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "word_count = 0\n",
    "\n",
    "for eng, vie in data:\n",
    "    for word in eng.split():\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = word_count\n",
    "            index_to_word[word_count] = word\n",
    "            word_count += 1\n",
    "    for word in vie.split():\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = word_count\n",
    "            index_to_word[word_count] = word\n",
    "            word_count += 1\n",
    "\n",
    "# Tạo tập dữ liệu dưới dạng số\n",
    "input_data = []\n",
    "output_data = []\n",
    "\n",
    "for eng, vie in data:\n",
    "    input_data.append([word_to_index[word] for word in eng.split()])\n",
    "    output_data.append([word_to_index[word] for word in vie.split()])\n",
    "\n",
    "# Thêm token <START> và <END> cho output\n",
    "START_TOKEN = word_count\n",
    "END_TOKEN = word_count + 1\n",
    "word_to_index[\"<START>\"] = START_TOKEN\n",
    "index_to_word[START_TOKEN] = \"<START>\"\n",
    "word_to_index[\"<END>\"] = END_TOKEN\n",
    "index_to_word[END_TOKEN] = \"<END>\"\n",
    "\n",
    "for i in range(len(output_data)):\n",
    "    output_data[i] = [START_TOKEN] + output_data[i] + [END_TOKEN]\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "embedding_dim = 50\n",
    "hidden_dim = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Khởi tạo các tham số mô hình\n",
    "def initialize_parameters(vocab_size, embedding_dim, hidden_dim):\n",
    "    parameters = {}\n",
    "    parameters['W_embed'] = np.random.randn(vocab_size, embedding_dim) * 0.01\n",
    "    parameters['W_enc'] = np.random.randn(hidden_dim, embedding_dim + hidden_dim) * 0.01\n",
    "    parameters['b_enc'] = np.zeros((hidden_dim, 1))\n",
    "    parameters['W_dec'] = np.random.randn(vocab_size, embedding_dim + hidden_dim) * 0.01\n",
    "    parameters['b_dec'] = np.zeros((vocab_size, 1))\n",
    "    parameters['W_attn'] = np.random.randn(hidden_dim, hidden_dim * 2) * 0.01\n",
    "    parameters['b_attn'] = np.zeros((hidden_dim, 1))\n",
    "    return parameters\n",
    "\n",
    "# Hàm nhúng từ\n",
    "def embed_word(word, W_embed):\n",
    "    return W_embed[word, :]\n",
    "\n",
    "# Hàm forward cho encoder\n",
    "def encoder_forward(X, parameters):\n",
    "    W_enc = parameters['W_enc']\n",
    "    b_enc = parameters['b_enc']\n",
    "    \n",
    "    h_prev = np.zeros((W_enc.shape[0], 1))\n",
    "    h_states = []\n",
    "    \n",
    "    for x in X:\n",
    "        x_embed = embed_word(x, parameters['W_embed'])\n",
    "        concat_input = np.vstack((x_embed.reshape(-1, 1), h_prev))\n",
    "        h_next = np.tanh(np.dot(W_enc, concat_input) + b_enc)\n",
    "        h_states.append(h_next)\n",
    "        h_prev = h_next\n",
    "    \n",
    "    return h_states\n",
    "\n",
    "# Hàm attention\n",
    "def attention(hidden_state, encoder_outputs, parameters):\n",
    "    W_attn = parameters['W_attn']\n",
    "    b_attn = parameters['b_attn']\n",
    "    \n",
    "    attention_weights = []\n",
    "    for h in encoder_outputs:\n",
    "        concat_h = np.vstack((hidden_state, h))\n",
    "        concat_h = concat_h.reshape(-1, 1)  # Đảm bảo concat_h có kích thước (hidden_dim * 2, 1)\n",
    "        score = np.dot(W_attn, concat_h) + b_attn\n",
    "        attention_weights.append(score)\n",
    "    \n",
    "    attention_weights = np.array(attention_weights).reshape(-1)\n",
    "    attention_weights = np.exp(attention_weights) / np.sum(np.exp(attention_weights))\n",
    "    \n",
    "    context_vector = np.zeros_like(encoder_outputs[0])\n",
    "    for i, h in enumerate(encoder_outputs):\n",
    "        context_vector += attention_weights[i] * h\n",
    "    \n",
    "    return context_vector\n",
    "\n",
    "# Hàm forward cho decoder\n",
    "def decoder_forward(Y, encoder_outputs, parameters):\n",
    "    W_dec = parameters['W_dec']\n",
    "    b_dec = parameters['b_dec']\n",
    "    \n",
    "    h_prev = encoder_outputs[-1]\n",
    "    outputs = []\n",
    "    \n",
    "    for y in Y:\n",
    "        y_embed = embed_word(y, parameters['W_embed'])\n",
    "        context_vector = attention(h_prev, encoder_outputs, parameters)\n",
    "        concat_input = np.vstack((y_embed.reshape(-1, 1), context_vector))\n",
    "        h_next = np.dot(W_dec, concat_input) + b_dec\n",
    "        outputs.append(h_next)\n",
    "        h_prev = h_next\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "# Hàm tính loss (sử dụng cross-entropy loss)\n",
    "def compute_loss(outputs, Y_true):\n",
    "    m = len(Y_true)\n",
    "    loss = 0\n",
    "    for i in range(m):\n",
    "        log_probs = -np.log(outputs[i][Y_true[i]])\n",
    "        loss += log_probs\n",
    "    loss = loss / m\n",
    "    return loss\n",
    "\n",
    "# Hàm huấn luyện mô hình\n",
    "def train(X_train, Y_train, vocab_size, embedding_dim, hidden_dim, num_epochs=100, learning_rate=0.01):\n",
    "    parameters = initialize_parameters(vocab_size, embedding_dim, hidden_dim)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for X, Y in zip(X_train, Y_train):\n",
    "            encoder_outputs = encoder_forward(X, parameters)\n",
    "            outputs = decoder_forward(Y, encoder_outputs, parameters)\n",
    "            \n",
    "            loss = compute_loss(outputs, Y)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            # Cập nhật các tham số\n",
    "            # Gradient descent cập nhật tham số\n",
    "            # Việc này yêu cầu tính toán đạo hàm, và cập nhật ngược các tham số\n",
    "            # Để đơn giản, chúng ta sẽ bỏ qua phần này ở đây\n",
    "            \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(X_train)}')\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "parameters = train(input_data, output_data, vocab_size, embedding_dim, hidden_dim, num_epochs=10)\n",
    "\n",
    "# Hàm dự đoán\n",
    "def predict(X, parameters):\n",
    "    encoder_outputs = encoder_forward(X, parameters)\n",
    "    outputs = decoder_forward(X, encoder_outputs, parameters)\n",
    "    predictions = np.argmax(outputs, axis=0)\n",
    "    return predictions\n",
    "\n",
    "# Ví dụ dự đoán\n",
    "X_test = [word_to_index[word] for word in \"hello\".split()]\n",
    "predictions = predict(X_test, parameters)\n",
    "print(\"Predictions:\", [index_to_word[idx] for idx in predictions])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
